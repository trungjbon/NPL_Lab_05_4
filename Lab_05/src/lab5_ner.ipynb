{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWovOATQz-KF"
      },
      "source": [
        "# Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIw9zBTEz850",
        "outputId": "b9b48391-d48f-4dc6-8be6-4fd15c4f9e94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
            "        num_rows: 14041\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
            "        num_rows: 3250\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
            "        num_rows: 3453\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"lhoestq/conll2003\")\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YIhgS6A2Y-c",
        "outputId": "2e50bb5d-ce25-47f0-fd81-06f5b7d7545f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example sentence:  ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "NER tags:  ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "train_sentences = dataset[\"train\"][\"tokens\"]\n",
        "train_tags = dataset[\"train\"][\"ner_tags\"]\n",
        "val_sentences = dataset[\"validation\"][\"tokens\"]\n",
        "val_tags = dataset[\"validation\"][\"ner_tags\"]\n",
        "test_sentences = dataset[\"test\"][\"tokens\"]\n",
        "test_tags = dataset[\"test\"][\"ner_tags\"]\n",
        "\n",
        "tag_names = [\"O\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-MISC\", \"I-MISC\"]\n",
        "train_tags_str = [[tag_names[tag] for tag in seq] for seq in train_tags]\n",
        "val_tags_str = [[tag_names[tag] for tag in seq] for seq in val_tags]\n",
        "test_tags_str = [[tag_names[tag] for tag in seq] for seq in test_tags]\n",
        "\n",
        "print(\"Example sentence: \", train_sentences[0])\n",
        "print(\"NER tags: \", train_tags_str[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOY_NkMc5vNo",
        "outputId": "4c95b0de-960d-430b-c4f0-cb488d80ab41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 23625\n",
            "Number of unique NER tags: 10\n",
            "NER tags mapping: {'I-PER': 0, 'B-LOC': 1, 'I-ORG': 2, 'B-PER': 3, 'I-MISC': 4, 'I-LOC': 5, 'B-ORG': 6, 'O': 7, 'B-MISC': 8, '<PAD>': 9}\n"
          ]
        }
      ],
      "source": [
        "# Từ điển từ\n",
        "vocab = set(word for sentence in train_sentences for word in sentence)\n",
        "word_to_ix = {word: idx for idx, word in enumerate(vocab)}\n",
        "\n",
        "word_to_ix[\"<PAD>\"] = len(word_to_ix)\n",
        "word_to_ix[\"<UNK>\"] = len(word_to_ix)\n",
        "\n",
        "print(\"Vocabulary size:\", len(word_to_ix))\n",
        "\n",
        "# Từ điển nhãn\n",
        "unique_tags = set(tag for seq in train_tags_str for tag in seq)\n",
        "tag_to_ix = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "\n",
        "tag_to_ix[\"<PAD>\"] = len(tag_to_ix)\n",
        "\n",
        "print(\"Number of unique NER tags:\", len(tag_to_ix))\n",
        "print(\"NER tags mapping:\", tag_to_ix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjQcdEnC6ws3"
      },
      "source": [
        "# Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RG8MlHoI6jio"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "PAD_WORD_IDX = word_to_ix[\"<PAD>\"]\n",
        "UNK_IDX = word_to_ix[\"<UNK>\"]\n",
        "PAD_TAG_IDX = tag_to_ix[\"<PAD>\"]\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, tags, word_to_ix, tag_to_ix):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.word_to_ix = word_to_ix\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tags = self.tags[idx]\n",
        "\n",
        "        sentence_idx = [self.word_to_ix.get(word, UNK_IDX) for word in sentence]\n",
        "        tag_idx = [self.tag_to_ix.get(tag, PAD_TAG_IDX) for tag in tags]\n",
        "\n",
        "        return torch.tensor(sentence_idx, dtype=torch.long), torch.tensor(tag_idx, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U4bGgpkW8Zqh"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sentences, tags = zip(*batch)\n",
        "\n",
        "    # pad các câu và nhãn về cùng độ dài\n",
        "    sentences_padded = pad_sequence(sentences, batch_first=True, padding_value=PAD_WORD_IDX)\n",
        "    tags_padded = pad_sequence(tags, batch_first=True, padding_value=PAD_TAG_IDX)\n",
        "\n",
        "    return sentences_padded, tags_padded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orcqD2JX8n49",
        "outputId": "60901ac9-c84b-4cf3-c9ed-d0efdcb34228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentences batch shape: torch.Size([32, 39])\n",
            "Tags batch shape: torch.Size([32, 39])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Dataset\n",
        "train_dataset = NERDataset(train_sentences, train_tags_str, word_to_ix, tag_to_ix)\n",
        "val_dataset = NERDataset(val_sentences, val_tags_str, word_to_ix, tag_to_ix)\n",
        "test_dataset = NERDataset(test_sentences, test_tags_str, word_to_ix, tag_to_ix)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Test batch\n",
        "for sentences_batch, tags_batch in train_loader:\n",
        "    print(\"Sentences batch shape:\", sentences_batch.shape)\n",
        "    print(\"Tags batch shape:\", tags_batch.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtqLtaWR_VtF"
      },
      "source": [
        "# Task 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnMFhVbc_YVW",
        "outputId": "3b701ae6-1784-43a6-9977-84d0ca1b1550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleRNNForTokenClassification(\n",
            "  (embedding): Embedding(23625, 100, padding_idx=23623)\n",
            "  (rnn): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRNNForTokenClassification(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, num_layers=1, dropout=0.1):\n",
        "        super(SimpleRNNForTokenClassification, self).__init__()\n",
        "\n",
        "        # 1. Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_WORD_IDX)\n",
        "\n",
        "        # 2. Bi-LSTM\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # 3. Linear layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # embedding\n",
        "        embeds = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Bi-LSTM\n",
        "        rnn_out, _ = self.rnn(embeds)  # [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        # Ánh xạ sang output_size\n",
        "        logits = self.fc(rnn_out)      # [batch_size, seq_len, output_size]\n",
        "\n",
        "        return logits\n",
        "\n",
        "# Tham số\n",
        "vocab_size = len(word_to_ix)       # từ điển từ\n",
        "embedding_dim = 100                # kích thước embedding\n",
        "hidden_dim = 128                   # số hidden units\n",
        "output_size = len(tag_to_ix)       # số lượng nhãn NER\n",
        "\n",
        "model = SimpleRNNForTokenClassification(vocab_size, embedding_dim, hidden_dim, output_size)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHwO42ypAY5Y"
      },
      "source": [
        "# Task 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VAzM-bPKAEzU"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Loss function, bỏ qua padding tokens\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TAG_IDX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3AlVaWwAfkh",
        "outputId": "ab1b8f5b-8f7b-45ed-f521-59f0fdd796ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3, Average Loss: 0.5952\n",
            "Epoch 2/3, Average Loss: 0.2667\n",
            "Epoch 3/3, Average Loss: 0.1550\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for sentences_batch, tags_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(sentences_batch)  # [batch, seq_len, num_classes]\n",
        "\n",
        "        # Reshape outputs & targets để tính loss\n",
        "        # CrossEntropyLoss expects [batch*seq_len, num_classes] and [batch*seq_len]\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])\n",
        "        tags_batch = tags_batch.view(-1)\n",
        "\n",
        "        loss = criterion(outputs, tags_batch)\n",
        "\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        count += 1\n",
        "\n",
        "    avg_loss = total_loss / count\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBYyX1jHCPBE"
      },
      "source": [
        "# Task 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "583NZGALCRfF",
        "outputId": "ebadd1e7-8d17-4faf-f106-3958d28c9714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "import torch\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "\n",
        "def evaluate(model, data_loader, tag_to_ix):\n",
        "    model.eval()\n",
        "    idx_to_tag = {idx: tag for tag, idx in tag_to_ix.items()}\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sentences_batch, tags_batch in data_loader:\n",
        "            outputs = model(sentences_batch)  # [batch, seq_len, num_classes]\n",
        "            preds = torch.argmax(outputs, dim=-1)  # [batch, seq_len]\n",
        "\n",
        "            # Chuyển tensor về list\n",
        "            preds = preds.tolist()\n",
        "            tags_batch = tags_batch.tolist()\n",
        "\n",
        "            for pred_seq, true_seq in zip(preds, tags_batch):\n",
        "                pred_tags = []\n",
        "                true_tags = []\n",
        "                for p, t in zip(pred_seq, true_seq):\n",
        "                    if t == PAD_TAG_IDX:  # bỏ qua token padding\n",
        "                        continue\n",
        "                    pred_tags.append(idx_to_tag[p])\n",
        "                    true_tags.append(idx_to_tag[t])\n",
        "                all_preds.append(pred_tags)\n",
        "                all_labels.append(true_tags)\n",
        "\n",
        "    # Token-level accuracy\n",
        "    correct = sum([p==t for seq_p, seq_t in zip(all_preds, all_labels) for p,t in zip(seq_p, seq_t)])\n",
        "    total = sum([len(seq) for seq in all_labels])\n",
        "    accuracy = correct / total\n",
        "    print(f\"Token-level Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # F1, Precision, Recall\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YWXuv6uECrT1"
      },
      "outputs": [],
      "source": [
        "def predict_sentence(model, sentence, word_to_ix, tag_to_ix):\n",
        "    if isinstance(sentence, str):\n",
        "        sentence = sentence.split()\n",
        "\n",
        "    model.eval()\n",
        "    idx_to_tag = {idx: tag for tag, idx in tag_to_ix.items()}\n",
        "\n",
        "    # Chuyển words sang indices\n",
        "    sentence_idx = [word_to_ix.get(w, UNK_IDX) for w in sentence]\n",
        "    sentence_tensor = torch.tensor(sentence_idx, dtype=torch.long).unsqueeze(0)  # [1, seq_len]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(sentence_tensor)  # [1, seq_len, num_classes]\n",
        "        preds = torch.argmax(outputs, dim=-1).squeeze(0).tolist()  # [seq_len]\n",
        "\n",
        "    predicted_tags = [idx_to_tag[p] for p in preds]\n",
        "    return list(zip(sentence, predicted_tags))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHaq25J-CwGW",
        "outputId": "d976c7da-22d6-4032-c416-ddc26e321b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation:\n",
            "Token-level Accuracy: 0.9332\n",
            "Precision: 0.7534, Recall: 0.6082, F1-score: 0.6731\n",
            "\n",
            "Test:\n",
            "Token-level Accuracy: 0.9100\n",
            "Precision: 0.6697, Recall: 0.4873, F1-score: 0.5641\n",
            "\n",
            " [('VNU', 'B-ORG'), ('University', 'I-ORG'), ('is', 'O'), ('located', 'O'), ('in', 'O'), ('Hanoi', 'O')]\n"
          ]
        }
      ],
      "source": [
        "# Đánh giá trên tập validation\n",
        "print(\"Validation:\")\n",
        "accuracy, precision, recall, f1 = evaluate(model, val_loader, tag_to_ix)\n",
        "# Đánh giá trên tập test\n",
        "print(\"\\nTest:\")\n",
        "accuracy, precision, recall, f1 = evaluate(model, test_loader, tag_to_ix)\n",
        "\n",
        "# Dự đoán cho một câu mới\n",
        "sentence = \"VNU University is located in Hanoi\"\n",
        "predictions = predict_sentence(model, sentence, word_to_ix, tag_to_ix)\n",
        "print(\"\\n\", predictions)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
